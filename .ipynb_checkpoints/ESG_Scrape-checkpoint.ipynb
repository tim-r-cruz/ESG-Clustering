{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AAPL - Apple Inc.']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import lxml\n",
    "from lxml import html\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "symbol = 'AAPL'\n",
    "\n",
    "url = f'https://finance.yahoo.com/quote/{symbol}/sustainability?p={symbol}'\n",
    "\n",
    "# Set up the request headers that we're going to use, to simulate\n",
    "# a request by the Chrome browser. Simulating a request from a browser\n",
    "# is generally good practice when building a scraper\n",
    "headers = {\n",
    "    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3',\n",
    "    'Accept-Encoding': 'gzip, deflate, br',\n",
    "    'Accept-Language': 'en-US,en;q=0.9',\n",
    "    'Cache-Control': 'max-age=0',\n",
    "    'Pragma': 'no-cache',\n",
    "    'Referrer': 'https://google.com',\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/77.0.3865.120 Safari/537.36'\n",
    "}\n",
    "\n",
    "# Fetch the page that we're going to parse, using the request headers\n",
    "# defined above\n",
    "page = requests.get(url, headers)\n",
    "\n",
    "# Parse the page with LXML, so that we can start doing some XPATH queries\n",
    "# to extract the data that we want\n",
    "tree = html.fromstring(page.content)\n",
    "\n",
    "# Smoke test that we fetched the page by fetching and displaying the H1 element\n",
    "tree.xpath(\"//h1/text()\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Environmental Ranking</th>\n",
       "      <th>Social Ranking</th>\n",
       "      <th>Governance Ranking</th>\n",
       "      <th>Company</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[99th percentile]</td>\n",
       "      <td>[56th percentile]</td>\n",
       "      <td>[43rd percentile]</td>\n",
       "      <td>AAPL - Apple Inc.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Environmental Ranking     Social Ranking Governance Ranking  \\\n",
       "0     [99th percentile]  [56th percentile]  [43rd percentile]   \n",
       "\n",
       "             Company  \n",
       "0  AAPL - Apple Inc.  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_rows = tree.xpath(\"//div[contains(@class, 'D(ib) Mt(10px) smartphone_Mt(5px)')]\")\n",
    "\n",
    "# Ensure that some table rows are found; if none are found, then it's possible\n",
    "# that Yahoo Finance has changed their page layout, or have detected\n",
    "# that you're scraping the page.\n",
    "assert len(table_rows) > 0\n",
    "\n",
    "parsed_rows = []\n",
    "\n",
    "for table_row in table_rows:\n",
    "    parsed_row = []\n",
    "    el = table_row.xpath(\"./div\")\n",
    "    \n",
    "    none_count = 0\n",
    "    \n",
    "    for rs in el:\n",
    "        try:\n",
    "            (text,) = rs.xpath('.//span/text()[1]')\n",
    "            parsed_row.append(text)\n",
    "        except ValueError:\n",
    "            pass\n",
    "    if (none_count < 4):\n",
    "        parsed_rows.append(parsed_row)\n",
    "\n",
    "df = pd.DataFrame([parsed_rows], columns=['Environmental Ranking',\n",
    "                                         'Social Ranking', \n",
    "                                         'Governance Ranking'])\n",
    "df['Company'] = tree.xpath(\"//h1/text()\")\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
